
# ğŸ§  Data Engineer Challenge

This project implements a full ETL pipeline that extracts data from a public API, loads raw data into a PostgreSQL container, transforms it using Python, and finally loads the result into a Microsoft SQL Server container.

The solution uses Docker, pandas, SQLAlchemy, and ODBC drivers to ensure cross-platform compatibility, making it easy to run on Windows, macOS, or Linux.

---

## ğŸš€ Project Structure

```
data-engineer-challenge/
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract.py              # Extracts data from JSONPlaceholder API
â”‚   â”œâ”€â”€ load_postgres.py        # Loads raw CSV data into PostgreSQL
â”‚   â”œâ”€â”€ transform.py            # Aggregates and transforms data
â”‚   â”œâ”€â”€ load_sqlserver.py       # Loads transformed data into SQL Server
â”‚   â””â”€â”€ test_connections.py     # Verifies both DB connections
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ db_connections.py       # Connection helpers for SQLAlchemy
â”œâ”€â”€ docker-compose.yml          # Defines Postgres & SQL Server containers
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
```

---

## ğŸ“¦ Prerequisites

- Python 3.12+
- Docker & Docker Compose
- `pip` installed in your Python environment

---

## ğŸ”§ Setup Instructions

### 1ï¸âƒ£ Clone the Project

```bash
git clone <your-repo-url>
cd data-engineer-challenge
```

### 2ï¸âƒ£ Start Docker Containers

```bash
docker-compose up -d
```

This launches:
- PostgreSQL (localhost:5432)
- SQL Server (localhost:1433)

### 3ï¸âƒ£ Create & Activate Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 4ï¸âƒ£ Install Python Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ“Š Run the ETL Pipeline

### âœ… Step-by-step

```bash
python etl/extract.py
python etl/load_postgres.py
python etl/transform.py
python etl/load_sqlserver.py
```

### âœ… Optional: Test DB Connections

```bash
python etl/test_connections.py
```

---

## ğŸ§  Troubleshooting

### On macOS (Apple Silicon - M1/M2):

```bash
export DYLD_LIBRARY_PATH="/opt/homebrew/lib:$DYLD_LIBRARY_PATH"
```

Add it to your `~/.zprofile` to persist.

### If `pyodbc` gives build issues:

```bash
ARCHFLAGS="-arch arm64" pip install pyodbc --no-binary :all:
```

### If `psycopg2` gives import errors:

Use the binary wheel:
```bash
pip install psycopg2-binary
```

---

## âœ… Output

Once successful, the following will be created:
- `users.csv`, `posts.csv` â†’ Raw extracted data
- `transformed_post_counts.csv` â†’ Aggregated result
- SQL tables: `users`, `posts` in Postgres; `user_post_counts` in SQL Server

---

## ğŸ‘¤ Author

**James Cundall**  
Email: cundall.alex@gmail.com  
GitHub: [github.com/<your-username>](https://github.com/)  
LinkedIn: [linkedin.com/in/alexcundall](https://linkedin.com/in/alexcundall)
